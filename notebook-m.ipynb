{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4089822,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, TimeDistributed, Flatten, LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\n\n\ndef create_cnn_lstm_model(input_shape, num_classes):\n    model = Sequential()\n\n   \n    model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=input_shape))\n    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n    model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n    model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\n    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n    model.add(TimeDistributed(Flatten()))\n\n   \n    model.add(LSTM(128, return_sequences=True))\n    model.add(Dropout(0.5))\n    model.add(LSTM(64))\n    model.add(Dropout(0.5))\n\n     Fully Connected\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n\n   \n    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model\n\n\ndef load_example_data():\n   \n    num_samples = 100 \n    num_frames = 30    \n    height, width, channels = 64, 64, 3  \n    num_classes = 10   \n\n    X_train = np.random.rand(num_samples, num_frames, height, width, channels) \n    y_train = np.random.randint(0, num_classes, num_samples) \n    X_test = np.random.rand(num_samples // 2, num_frames, height, width, channels)  \n    y_test = np.random.randint(0, num_classes, num_samples // 2)  \n\n   \n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n\n    return X_train, X_test, y_train, y_test\n\n\nX_train, X_test, y_train, y_test = load_example_data()\n\n\ninput_shape = (None, 64, 64, 3)  \nnum_classes = 10\n\n\nmodel = create_cnn_lstm_model(input_shape, num_classes)\n\n\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n\n\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Loss: {loss}')\nprint(f'Test Accuracy: {accuracy}')\n\n\nmodel.save('sign_language_cnn_lstm.h5')\n\n\nmodel = load_model('sign_language_cnn_lstm.h5')\n\n\ndef prepare_test_sample(num_frames=30, height=64, width=64, channels=3):\n    \n    test_sample = np.random.rand(1, num_frames, height, width, channels)\n    return test_sample\n\nX_new = prepare_test_sample()\n\n\npredictions = model.predict(X_new)\npredicted_class = np.argmax(predictions)\n\nprint(\"Predicted Class:\", predicted_class)\n\n\nfor i, prob in enumerate(predictions[0]):\n    print(f\"Class {i}: {prob:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T19:22:40.781406Z","iopub.execute_input":"2025-03-23T19:22:40.781830Z","iopub.status.idle":"2025-03-23T19:47:35.785567Z","shell.execute_reply.started":"2025-03-23T19:22:40.781787Z","shell.execute_reply":"2025-03-23T19:47:35.783956Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 21s/step - accuracy: 0.0787 - loss: 2.3781 - val_accuracy: 0.1200 - val_loss: 2.3263\nEpoch 2/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 15s/step - accuracy: 0.1465 - loss: 2.3358 - val_accuracy: 0.1200 - val_loss: 2.3190\nEpoch 3/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.0992 - loss: 2.4146 - val_accuracy: 0.1200 - val_loss: 2.3131\nEpoch 4/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 15s/step - accuracy: 0.1138 - loss: 2.3868 - val_accuracy: 0.1200 - val_loss: 2.3101\nEpoch 5/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 15s/step - accuracy: 0.1508 - loss: 2.3161 - val_accuracy: 0.1200 - val_loss: 2.3137\nEpoch 6/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.0928 - loss: 2.3726 - val_accuracy: 0.1200 - val_loss: 2.3097\nEpoch 7/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.1015 - loss: 2.4110 - val_accuracy: 0.1200 - val_loss: 2.3012\nEpoch 8/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.0798 - loss: 2.2888 - val_accuracy: 0.1200 - val_loss: 2.2949\nEpoch 9/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 15s/step - accuracy: 0.0768 - loss: 2.3988 - val_accuracy: 0.1200 - val_loss: 2.2886\nEpoch 10/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 24s/step - accuracy: 0.0615 - loss: 2.3726 - val_accuracy: 0.1200 - val_loss: 2.2856\nEpoch 11/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.1362 - loss: 2.3151 - val_accuracy: 0.1200 - val_loss: 2.2856\nEpoch 12/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.0777 - loss: 2.3804 - val_accuracy: 0.1200 - val_loss: 2.2852\nEpoch 13/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.1181 - loss: 2.2488 - val_accuracy: 0.1200 - val_loss: 2.2853\nEpoch 14/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.1610 - loss: 2.2462 - val_accuracy: 0.1200 - val_loss: 2.2877\nEpoch 15/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.1232 - loss: 2.2882 - val_accuracy: 0.1200 - val_loss: 2.2907\nEpoch 16/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16s/step - accuracy: 0.1357 - loss: 2.2900 - val_accuracy: 0.1200 - val_loss: 2.2924\nEpoch 17/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 15s/step - accuracy: 0.0738 - loss: 2.3256 - val_accuracy: 0.1200 - val_loss: 2.2920\nEpoch 18/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 15s/step - accuracy: 0.0695 - loss: 2.3441 - val_accuracy: 0.1200 - val_loss: 2.2928\nEpoch 19/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 21s/step - accuracy: 0.1260 - loss: 2.2804 - val_accuracy: 0.1200 - val_loss: 2.2943\nEpoch 20/20\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 15s/step - accuracy: 0.2029 - loss: 2.2605 - val_accuracy: 0.1200 - val_loss: 2.2954\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732ms/step - accuracy: 0.1321 - loss: 2.2989\nTest Loss: 2.295405387878418\nTest Accuracy: 0.11999999731779099\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\nPredicted Class: 5\nClass 0: 0.0996\nClass 1: 0.0907\nClass 2: 0.1149\nClass 3: 0.0919\nClass 4: 0.0680\nClass 5: 0.1294\nClass 6: 0.1046\nClass 7: 0.0845\nClass 8: 0.1109\nClass 9: 0.1056\n","output_type":"stream"}],"execution_count":1}]}